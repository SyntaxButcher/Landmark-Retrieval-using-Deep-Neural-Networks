# -*- coding: utf-8 -*-
"""preprocess2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fA4BRWaqacQWCh0mgm3wZrGTxX6bu2e6
"""

import csv
import os
from sklearn.model_selection import train_test_split
# from google.colab import files

# files.upload()

csv_path = './kaggle_datasets/train.csv'
new_csv_path = './kaggle_datasets/train_new.csv'
# train_split_path = './kaggle_datasets/train_split.csv'
# test_split_path = './kaggle_datasets/test_split.csv'

# csv_path = './train.csv'
# new_csv_path = './train_new.csv'
# train_split_path = './train_split.csv'
# test_split_path = './test_split.csv'


with open(csv_path, 'r') as f:
    reader = csv.reader(f)
    next(reader)
    column_list = [int(row[1]) for row in reader]

classes = list(set(column_list))
print(len(classes))
classes.sort()

class_dict = {}
for i in range(0, len(classes)):
  class_dict[str(classes[i])] = str(i)

with open(csv_path, 'r') as f:
    reader = csv.reader(f)
    
    # Open the new_train.csv file and create a CSV writer object
    with open(new_csv_path, 'w', newline='') as g:
        writer = csv.writer(g)
        
        # Write the header row to the new_train.csv file
        writer.writerow(['id', 'landmark_id'])
        
        # Iterate over the rows in the train.csv file and append '.jpg' to the image_id column
        for i, row in enumerate(reader):
            if i == 0:
                continue
            image_id = row[0]
            new_image_id = image_id + '.jpg'
            row[0] = new_image_id

            row[1] = class_dict[row[1]]
            
            # Write the modified row to the new_train.csv file
            writer.writerow(row)

import pandas as pd

# Load the train.csv file into a Pandas dataframe
df = pd.read_csv(new_csv_path)

# Get a list of all the classes
classes = df['landmark_id'].unique().tolist()

# Split each class into train and test sets
train_dfs = []
test_dfs = []
for cls in classes:
    cls_df = df[df['landmark_id'] == cls]
    if len(cls_df) < 4: # check if class contains less than 5 images
      train_dfs.append(cls_df)
    else:
      train_df, test_df = train_test_split(cls_df, test_size=0.2, random_state=42)
      train_dfs.append(train_df)
      test_dfs.append(test_df)

# Combine all the train and test sets into single dataframes
train_df = pd.concat(train_dfs)
test_df = pd.concat(test_dfs)

# Save the train and test sets to separate CSV files
train_df.to_csv('train_split.csv', index=False)
test_df.to_csv('test_split.csv', index=False)

csv_path = './train_split.csv'

with open(csv_path, 'r') as f:
    reader = csv.reader(f)
    next(reader)
    column_list = [int(row[1]) for row in reader]
    

classes = list(set(column_list))
print(f'Num classes in  train_split: {len(classes)}')

count = 0
with open(csv_path, 'r') as f:
    reader = csv.reader(f)
    next(reader)
    count = sum(1 for row in reader)

print(f'Data count in train_split: {count}')

csv_path = './test_split.csv'
count = 0
with open(csv_path, 'r') as f:
    reader = csv.reader(f)
    next(reader)
    column_list = [int(row[1]) for row in reader]

classes = list(set(column_list))
print(f'Num classes in  train_split: {len(classes)}')

with open(csv_path, 'r') as f:
    reader = csv.reader(f)
    next(reader)
    count = sum(1 for row in reader)

print(f'Data count in test split: {count}')

with open(new_csv_path, 'r') as f:
    reader = csv.reader(f)
    next(reader)
    column_list = [int(row[1]) for row in reader]

classes = list(set(column_list))
print(f'Num classes in  entire dataset: {len(classes)}')

count = 0
with open(new_csv_path, 'r') as f:
    reader = csv.reader(f)
    next(reader)
    count = sum(1 for row in reader)

print(f'Data count in entire dataset: {count}')

# files.download('./train_split.csv')
# files.download('./test_split.csv')
# files.download('./train_new.csv')