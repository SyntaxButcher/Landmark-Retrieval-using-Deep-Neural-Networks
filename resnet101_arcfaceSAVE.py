# -*- coding: utf-8 -*-
"""ResNet101_Arcface.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LogFZsaH7AGawIgDnng4qanmI7CKGOe0
"""

import tensorflow as tf
from tensorflow.keras.applications import ResNet101V2 
from tensorflow.keras import layers, Model
from tensorflow.keras.layers import Layer
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import pandas as pd
from PIL import Image
import math
import tensorflow.keras.backend as K
from tensorflow.keras.initializers import Constant
from tensorflow.python.keras.utils import tf_utils
import time
import os
from tqdm import tqdm

def _resolve_training(layer, training):
    if training is None:
        training = K.learning_phase()
    if isinstance(training, int):
        training = bool(training)
    if not layer.trainable:
        # When the layer is not trainable, override the value
        training = False
    return tf_utils.constant_value(training)

class ArcFace(layers.Layer):
    def __init__(self, num_classes=10, margin=0.5, scale=64, **kwargs):
        super(ArcFace, self).__init__(**kwargs)
        self.num_classes = num_classes
        self.margin = margin
        self.scale = scale

    def build(self, input_shape):
        self.W = self.add_weight(name='W',
                                 shape=(input_shape[-1], self.num_classes),
                                 initializer='glorot_uniform',
                                 trainable=True)

    def call(self, inputs, labels=None):
        cosine = tf.matmul(tf.nn.l2_normalize(inputs, axis=1), tf.nn.l2_normalize(self.W, axis=0))
        if labels is None:
            return self.scale * cosine
        else:
            one_hot = tf.one_hot(labels, depth=self.num_classes)
            theta = tf.acos(tf.clip_by_value(cosine, -1.0 + tf.keras.backend.epsilon(), 1.0 - tf.keras.backend.epsilon()))
            marginal_cosine = tf.cos(theta + self.margin)
            hard_example = tf.cast(tf.greater(cosine, one_hot - self.margin), tf.float32)
            cos_m = tf.where(one_hot == 1, marginal_cosine, cosine - one_hot * self.margin)
            output = self.scale * tf.where(one_hot == 1, cos_m, hard_example * (cosine - self.margin * one_hot))
            return output

class CustomCallback(tf.keras.callbacks.Callback):
    def __init__(self, threshold=0.95):
        self.threshold = threshold
        super().__init__()

    def on_train_batch_end(self, batch, logs=None):
        if logs['accuracy'] >= self.threshold:
            print(f"accuracy reached {self.threshold * 100:.2f}%, stopping training.")
            self.model.stop_training = True

def ResNet101(input_shape, num_classes):
    pretrained_model = ResNet101V2(include_top=False, weights='imagenet', input_shape=input_shape)

    for layer in pretrained_model.layers:
        layer.trainable = False

    # freeze_layers = ['conv2', 'conv3', 'conv4']
    # for layer in pretrained_model.layers:
    #     if any(layer.name.startswith(f) for f in freeze_layers):
    #         layer.trainable = False
    #     else:
    #         layer.trainable = True

    x = pretrained_model.output
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(512, activation=tf.nn.relu)(x)

    predictions = ArcFace(num_classes=num_classes, margin=0.3, scale=46)(x)

    return Model(pretrained_model.input, predictions)

train_csv_path = './kaggle_datasets/train_split.csv'
test_csv_path = './kaggle_datasets/test_split.csv'

traindf = pd.read_csv(train_csv_path, dtype=str)
testdf = pd.read_csv(test_csv_path, dtype=str)

print('Dataframes created!')
t1 = time.time()

train_datagen = ImageDataGenerator(rescale=1.0/255.0)
train_generator = train_datagen.flow_from_dataframe(
    traindf,
    directory='./kaggle_datasets/train_dir/', 
    x_col='id',
    y_col='landmark_id',
    target_size=(300,300),
    batch_size=128,
    shuffle=True,
    class_mode="sparse",   
)
t2 = time.time()
print(f"Train ImageDataGenerators created. Time taken: {t2-t1}")

test_datagen = ImageDataGenerator(rescale=1.0/255.0)
test_generator = test_datagen.flow_from_dataframe(
    testdf,
    directory='./kaggle_datasets/train_dir/', 
    x_col='id',
    y_col='landmark_id',
    target_size=(300,300),
    batch_size=64,
    shuffle=True,
    class_mode="sparse",   
)
t3 = time.time()
print(f"Test ImageDataGenerators created. Time taken: {t3-t2}")

model = ResNet101(input_shape=(300, 300, 3), num_classes=81313)

model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])

model_save_path = 'model_weights.h5'
# Check if the saved weights file exists and load the weights
if os.path.exists(model_save_path):
    model.load_weights(model_save_path)
    print("Weights loaded!")
custom_callback = CustomCallback()
model.fit(train_generator, epochs=2, callbacks=[custom_callback])

model.save_weights(model_save_path)
print("Weights saved!")

# # With this custom loop:
# num_epochs = 1
# for epoch in range(num_epochs):
#     print(f"Epoch {epoch + 1}/{num_epochs}")
#     with tqdm(total=len(train_generator), ncols=100) as pbar:
#         for batch_idx, batch in enumerate(train_generator):
#             x_batch, y_batch = batch
#             loss, accuracy = model.train_on_batch(x_batch, y_batch)
#             pbar.set_description(f"loss: {loss:.4f}, accuracy: {accuracy:.4f}")
#             pbar.update(1)

#             if batch_idx + 1 == len(train_generator):
#                 break

#         pbar.close()
#     model.save_weights(model_save_path)


